{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: \n",
    "\n",
    "### 2016 U.S. POTUS Primary Election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', 1300)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import time\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///database.sqlite\n",
    "try:    \n",
    "    db = sqlite3.connect('database.sqlite')\n",
    "    c = db.cursor()\n",
    "    print \"Successfully connected to the database\"\n",
    "except IntegrityError:\n",
    "    print\"Did not successfully connect to database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%sql SELECT * FROM primary_results\n",
    "%sql ALTER TABLE primary_results ADD COLUMN county_state TEXT;\n",
    "%sql UPDATE primary_results SET county_state = (county || \"_\" || state_abbreviation);\n",
    "%sql UPDATE primary_results SET candidate = Replace(candidate,' ','_');\n",
    "\n",
    "#Create Republican Table:\n",
    "%sql CREATE TABLE Republicans AS SELECT * FROM primary_results;\n",
    "%sql DELETE FROM Republicans WHERE(party ='Democrat') \n",
    "\n",
    "#Create Democrat Table:\n",
    "%sql CREATE TABLE Democrats AS SELECT * FROM primary_results;\n",
    "%sql DELETE FROM Democrats WHERE(party ='Republican') \n",
    "\n",
    "#Update County Facts Table:\n",
    "%sql UPDATE county_facts SET state_abbreviation = NULL WHERE state_abbreviation = '';\n",
    "%sql DELETE FROM county_facts WHERE state_abbreviation IS NULL;\n",
    "%sql ALTER TABLE county_facts ADD COLUMN county_state TEXT;\n",
    "%sql UPDATE county_facts SET area_name = SUBSTR(area_name,1, LENGTH(area_name)-7);\n",
    "%sql UPDATE county_facts SET county_state = (area_name || \"_\" || state_abbreviation);\n",
    "%sql UPDATE county_facts SET county_state = REPLACE(county_state,'\"','');\n",
    "\n",
    "#Output County_Facts_Description as CSV file (.mode csv)\n",
    "#%sql .output county_facts_dict.csv # command in terminal\n",
    "\n",
    "SQL Commands used in terminal:\n",
    "\n",
    "#SQL TABLES FOR TO GROUP WINNER OF EACH COUNTY:\n",
    "\n",
    "#Identify the Republican winner in each county:\n",
    "%sql SELECT state, state_abbreviation, county, fips, party, candidate, MAX(votes), fraction_votes, county_state FROM Republicans GROUP BY county ORDER BY state;\n",
    "%sql CREATE TABLE Republican_Winner(state TEXT NOT NULL, state_abbreviation TEXT NOT NULL, county TEXT NOT NULL, fips INTEGER NOT NULL, party TEXT NOT NULL, candidate TEXT NOT NULL, votes INTEGER NOT NULL, fraction_votes INTEGER NOT NULL, county_state TEXT NOT NULL);\n",
    "#.import republican_winners.csv Republican_Winner\n",
    "\n",
    "#Identify the Democrat winner in each county:\n",
    "%sql SELECT state, state_abbreviation, county, fips, party, candidate, MAX(votes), fraction_votes, county_state FROM Democrats GROUP BY county ORDER BY state;\n",
    "%sql CREATE TABLE Democrat_Winner(state TEXT NOT NULL, state_abbreviation TEXT NOT NULL, county TEXT NOT NULL, fips INTEGER NOT NULL, party TEXT NOT NULL, candidate TEXT NOT NULL, votes INTEGER NOT NULL, fraction_votes INTEGER NOT NULL, county_state TEXT NOT NULL);\n",
    "#.import democrat_winners.csv Democrat_Winner \n",
    "\n",
    "# Join Tables (county_facts and Republican/Democrat winner)\n",
    "%sql SELECT * FROM Republican_Winner INNER JOIN county_facts WHERE Republican_Winner.county_state = county_facts.county_state;\n",
    "%sql SELECT * FROM Democrat_Winner INNER JOIN county_facts WHERE Democrat_Winner.county_state = county_facts.county_state;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate Dataframe\n",
    "df_primary_results = pd.read_sql_query('SELECT * FROM primary_results', db) #Primary Results \n",
    "df_county_facts = pd.read_sql_query('SELECT * FROM county_facts',db) #County Facts\n",
    "df_republicans = pd.read_sql_query('SELECT * FROM Republicans',db) # Republican Table\n",
    "df_democrats = pd.read_sql_query('SELECT * FROM Democrats', db) # Democrat Table\n",
    "\n",
    "#County Facts Dictionary:\n",
    "df_county_facts_dictionary = pd.read_sql_query('SELECT * FROM county_facts_dictionary ',db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Primary results\n",
    "df_primary_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# County Facts data\n",
    "df_county_facts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#shape of tables:\n",
    "prim = df_primary_results.shape[0]\n",
    "rep = df_republicans.shape[0]\n",
    "dem = df_democrats.shape[0]\n",
    "print \"Primary Results...\"\n",
    "print \"Total Number of Elements = {}; Republican: {}, Democrat :{}\".format(prim,rep,dem)\n",
    "print \"Number of Features =\", df_primary_results.shape[1]\n",
    "\n",
    "#County Facts (shape):\n",
    "print \"\\nCounty Facts...\"\n",
    "print \"Total Number of Elements =\", df_county_facts.shape[0]\n",
    "print \"Number of Features =\", df_county_facts.shape[1] -4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Primary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "votes_sum = pd.read_sql_query('SELECT candidate, party, sum(votes) as sum_votes \\\n",
    "    FROM primary_results GROUP BY candidate, party ORDER BY sum_votes desc, party;',db)\n",
    "#Candidate who suspended campaign: (drop from df)\n",
    "to_del = votes_sum.loc[votes_sum['candidate'].isin(['Jeb_Bush', 'Ben_Carson','Rand_Paul',\n",
    "    'Chris_Christie','Carly_Fiorina','Rick_Santorum','Mike_Huckabee',\n",
    "    \"Martin_O'Malley\",'Marco_Rubio','_No_Preference','_Uncommitted'])].index.tolist()\n",
    "votes = votes_sum.drop(to_del)\n",
    "\n",
    "#Plots\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(y = 'candidate', x = 'sum_votes', data = votes, palette = \"BuGn_r\")\n",
    "sns.plt.title('Total Votes per Candidate - Remaining', fontsize = 18)\n",
    "\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(y = 'candidate', x = 'sum_votes', data = votes_sum, palette = \"BuGn_r\")\n",
    "sns.plt.title('Total Votes per Candidate - All', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# republican winner by county:\n",
    "rep_winner_county = pd.read_sql_query('SELECT candidate, count(candidate) \\\n",
    "    as count_county FROM Republican_Winner GROUP BY candidate ORDER BY count_county desc', db)\n",
    "# democrat winner by county:\n",
    "dem_winner_county = pd.read_sql_query('SELECT candidate, count(candidate) \\\n",
    "    as count_county FROM Democrat_Winner GROUP BY candidate ORDER BY count_county desc', db)\n",
    "\n",
    "#plots\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(x = 'candidate', y = 'count_county', data = rep_winner_county, palette=\"PuBuGn_d\")\n",
    "sns.plt.title('Total Republican Primary Counties Won', fontsize = 18)\n",
    "\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(x = 'candidate', y = 'count_county', data = dem_winner_county, palette=\"PuBuGn_d\")\n",
    "sns.plt.title('Total Democrat Primary Counties Won', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Republican Party:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dataframe for Republican winners per county w/ county facts:\n",
    "republican_data = pd.read_csv(\"republican_winners_county_facts.csv\")\n",
    "#drop repeated rows from merge\n",
    "republican_data.drop(republican_data.columns[[1,9,10,11,63]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.lmplot(x=\"SEX255214\", y = \"fraction_votes\", data = republican_data, hue = \"candidate\", ci=False)\n",
    "g.set_xlabels(\"Sex\", size = 18)\n",
    "g.set_ylabels(\"Fraction Votes\", size = 18)\n",
    "g.set(xlim=(20,60), ylim=(0,1))\n",
    "sns.plt.title('Republican Winner', fontsize = 20)\n",
    "\n",
    "g = sns.lmplot(x=\"RHI125214\", y = \"fraction_votes\", data = republican_data, hue = \"candidate\", ci=False)\n",
    "g.set_xlabels(\"White\", size = 18)\n",
    "g.set_ylabels(\"Fraction Votes\", size = 18)\n",
    "g.set(ylim=(0,1))\n",
    "sns.plt.title('Republican Winner', fontsize = 20)\n",
    "\n",
    "g = sns.lmplot(x=\"VET605213\", y = \"fraction_votes\", data = republican_data, hue = \"candidate\", ci=False)\n",
    "g.set_xlabels(\"Veterans\", size = 18)\n",
    "g.set_ylabels(\"Fraction Votes\", size = 18)\n",
    "g.set(ylim=(0,1))\n",
    "sns.plt.title('Republican Winner', fontsize = 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training/Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, remove all candidates who suspended campaign:\n",
    "to_del = republican_data.loc[republican_data['candidate'].isin(['Jeb_Bush', 'Ben_Carson','Rand_Paul','Chris_Christie','Carly_Fiorina','Rick_Santorum','Mike_Huckabee',\"Marco_Rubio\",\"_No_Preference\",\"_Uncommitted\"])].index.tolist()\n",
    "republican_data = republican_data.drop(to_del)\n",
    "\n",
    "# Arranging Data for Features & Targets\n",
    "republican_data = republican_data.replace(['Donald_Trump','Ted_Cruz','John_Kasich'],[1,2,3])\n",
    "\n",
    "x_vars = list(republican_data.columns[8:]) \n",
    "x_vars= republican_data[x_vars] # Features\n",
    "y_vars = republican_data['candidate'] # Target Labels\n",
    "df_rep = pd.concat([x_vars,y_vars],axis=1) #combine Feautres/Target into one dataframe\n",
    "\n",
    "feature_cols = list(df_rep.columns[:-1])  # all columns but last are features\n",
    "target_col = df_rep.columns[-1]  # last column is the target/label\n",
    "\n",
    "X_all = df_rep[feature_cols]  # feature values \n",
    "y = df_rep[target_col]  # corresponding targets/labels\n",
    "\n",
    "#print X_all\n",
    "#print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_all = df_rep.shape[0]\n",
    "num_train = int(num_all - (num_all*.25))\n",
    "num_test = num_all - num_train\n",
    "\n",
    "def Stratified_Shuffle_Split(X,y,num_test):\n",
    "    sss = StratifiedShuffleSplit(y, 10, test_size=num_test, random_state = 42)\n",
    "    for train_index, test_index in sss:\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y, num_test)\n",
    "print \"Training Set: {0:.2f} Samples\".format(X_train.shape[0])\n",
    "print \"Testing Set: {0:.2f} Samples\".format(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "X_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#covariance matrix\n",
    "cov_matrix = republican_data.cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Eigenvalue and Eigenvector of covariance matrix:\n",
    "columns = X_all.columns\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "sum_ev = sum(eig_vals)\n",
    "#Explained Variance Ratio\n",
    "print eig_vals/sum_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "columns = X_all.columns\n",
    "scale = preprocessing.scale(X_all)\n",
    "df_scale = pd.DataFrame(scale, columns=columns)\n",
    "#df_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def doPCA():\n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(df_scale)\n",
    "    return pca\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "pca = doPCA()\n",
    "columns = X_all.columns\n",
    "df_pca = pd.DataFrame(pca.components_, columns = columns, index=['1', '2', '3', '4','5'])\n",
    "df_pca.index.names = ['PC']\n",
    "print \"Principal Component Analysis:\"\n",
    "print df_pca\n",
    "\n",
    "ex_var = pca.explained_variance_ratio_\n",
    "df_var = pd.Series(ex_var,index=['1','2','3','4','5'])\n",
    "df_var.sort(ascending=False)\n",
    "\n",
    "df_var.index.names = ['PC']\n",
    "print \"\\nExplained Variance of Each Component:\"\n",
    "print df_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8,5))\n",
    "x = np.arange(1,6) # Number of PC's\n",
    "y= np.cumsum(ex_var)# cumulative sum of explained variance\n",
    "pl.plot(x,y,marker =\"o\", mfc='#780000', color = '#CC0000')\n",
    "pl.xlabel(\"No. of PC Components\", fontsize = 14)\n",
    "pl.ylabel(\"Cumulative Explained Variance Ratio\", fontsize =14)\n",
    "pl.title(\"No. of PC Components vs Explained Variance Ratio\", fontsize = 16)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8,6))\n",
    "pl.bar(range(1,6),ex_var, alpha=.55, align='center', label='Individual Explained Variance', color = 'b')\n",
    "pl.ylabel('Explained Variance Ratio', fontsize = 14)\n",
    "pl.xlabel('Principal Components', fontsize  =14)\n",
    "pl.title('Explained Variance', fontsize = 16)\n",
    "pl.show()\n",
    "\n",
    "#Slope:\n",
    "X1, Y1 = 1, 0.901574\n",
    "X2, Y2 = 2, 0.057343\n",
    "X3, Y3 = 3, 0.037759\n",
    "X4, Y4 = 4, 0.003239\n",
    "X5, Y5 = 5, 0.000049\n",
    "slope1 = (Y2-Y1)/(X2-X1)\n",
    "slope2 = (Y3-Y2)/(X3-X2)\n",
    "slope3= (Y4-Y3)/(X4-X3)\n",
    "print \"Slope1:\", slope1\n",
    "print \"Slope2:\", slope2\n",
    "print \"Slope3:\", slope3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: Train and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}:\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    train_clf_time = end - start\n",
    "    print \"Training Time (secs): {:.3f}\".format(train_clf_time)\n",
    "    return train_clf_time\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print \"Predicting labels using {}:\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    prediction_time = end - start\n",
    "    print \"Prediction Time (secs): {:.3f}\".format(prediction_time)\n",
    "    return (f1_score(target.values, y_pred, pos_label= None, average = 'weighted'), prediction_time)\n",
    "\n",
    "# Train and Predict\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    print \"Training set size: {}\".format(len(X_train))\n",
    "    print \"Testing set size: {}\".format(len(X_test))\n",
    "    train_diff = train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Train and predict on diff. training set sizes\n",
    "    f1_score_train, pred_time_train = predict_labels(clf, X_train, y_train)\n",
    "    print \"F1 score for training set:\",(f1_score_train)\n",
    "    # Predict on test data\n",
    "    f1_score_test, pred_time_test = predict_labels(clf, X_test, y_test)\n",
    "    print \"F1 score for test set:\",(f1_score_test)\n",
    "    \n",
    "    return (f1_score_train, f1_score_test, train_diff, pred_time_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "def run_all_models(classifiers):\n",
    "    for clf in classifiers:\n",
    "        df = pd.DataFrame(columns = [\n",
    "                    'Training_Size',\n",
    "                    'Testing_Size',\n",
    "                    'Training_Time',\n",
    "                    'Prediction_Time',\n",
    "                    'F1_Training_Score',\n",
    "                    'F1_Testing_Score'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y, num_test)\n",
    "        \n",
    "        num_times_to_run = 10\n",
    "        sizes = [X_test.shape[0]]\n",
    "        for size in sizes: \n",
    "            for x in range(0, num_times_to_run): \n",
    "                f1_score_train, f1_score_test, train_time, pred_time_test = train_predict(clf, X_train[:size], y_train[:size], X_test, y_test)\n",
    "                        \n",
    "                df = df.append({\n",
    "                        'Training_Size': len(X_train[:size]),\n",
    "                        'Testing_Size': X_test.shape[0],\n",
    "                        'Training_Time': train_time,\n",
    "                        'Prediction_Time': pred_time_test,\n",
    "                        'F1_Training_Score': f1_score_train,\n",
    "                        'F1_Testing_Score': f1_score_test}, \n",
    "                        ignore_index= True)\n",
    "            \n",
    "            df = df[(df.Training_Size == size)]\n",
    "            df_mean = df.mean()\n",
    "        \n",
    "            print \"**********************************************************\"\n",
    "            print \"Mean Statistics:\"\n",
    "            print df_mean\n",
    "            print \"**********************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_all_models([clf_RF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iterate_fit_predict(number_runs):\n",
    "    f1_scores = []\n",
    "    \n",
    "    for num in range(0, number_runs):\n",
    "        X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y, num_test)\n",
    "        clf = clf_RF\n",
    "        parameters = {'max_depth':(1,2,3,4,5,6,7,8,9,10)}\n",
    "        \n",
    "        clf = GridSearchCV(clf_RF, parameters, scoring = 'f1')\n",
    "        \n",
    "        #Fit classifier to training data:\n",
    "        clf.fit(X_train,y_train)\n",
    "        f1_scores.append(clf.score(X_test,y_test))\n",
    "        #clf = clf.best_estimator_\n",
    "    \n",
    "    df_f1 = pd.Series(f1_scores)\n",
    "    print clf\n",
    "    print \"\\nF1 Scores:\"\n",
    "    print df_f1\n",
    "    \n",
    "    print \"\\n Average F1 Test Scores:\"\n",
    "    print df_f1.mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterate_fit_predict(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Democrat Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataframe for Republican winners per county w/ county facts:\n",
    "democrat_data = pd.read_csv(\"democrat_winners_county_facts.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
