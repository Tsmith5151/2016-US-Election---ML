{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project\n",
    "\n",
    "### 2016 U.S. POTUS Primary Election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', 1300)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import networkx as nx\n",
    "import pygraphviz\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import time\n",
    "import pydot\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image \n",
    "from sklearn.tree import export_graphviz\n",
    "from StringIO import StringIO\n",
    "from io import BytesIO\n",
    "from IPython.display import Image \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%sqlite_execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///database.sqlite\n",
    "try:    \n",
    "    db = sqlite3.connect('database.sqlite')\n",
    "    c = db.cursor()\n",
    "    print \"Successfully connected to the database\"\n",
    "except IntegrityError:\n",
    "    print\"Did not successfully connect to database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%sql SELECT * FROM primary_results\n",
    "\n",
    "%sql ALTER TABLE primary_results ADD COLUMN county_state TEXT;\n",
    "%sql UPDATE primary_results SET county_state = (county || \"_\" || state_abbreviation);\n",
    "%sql UPDATE primary_results SET candidate = Replace(candidate,' ','_');\n",
    "\n",
    "'''Create Republican Table:'''\n",
    "%sql CREATE TABLE Republicans AS SELECT * FROM primary_results;\n",
    "%sql DELETE FROM Republicans WHERE(party ='Democrat') \n",
    "\n",
    "'''Create Democrat Table:'''\n",
    "%sql CREATE TABLE Democrats AS SELECT * FROM primary_results;\n",
    "%sql DELETE FROM Democrats WHERE(party ='Republican') \n",
    "\n",
    "'''Update County Facts Table:'''\n",
    "%sql UPDATE county_facts SET state_abbreviation = NULL WHERE state_abbreviation = '';\n",
    "%sql DELETE FROM county_facts WHERE state_abbreviation IS NULL;\n",
    "%sql ALTER TABLE county_facts ADD COLUMN county_state TEXT;\n",
    "%sql UPDATE county_facts SET area_name = SUBSTR(area_name,1, LENGTH(area_name)-7);\n",
    "%sql UPDATE county_facts SET county_state = (area_name || \"_\" || state_abbreviation);\n",
    "%sql UPDATE county_facts SET county_state = REPLACE(county_state,'\"','');\n",
    "\n",
    "#Output County_Facts_Description as CSV file (.mode csv)\n",
    "#%sql .output county_facts_dict.csv # command in terminal\n",
    "\n",
    "\n",
    "'''SQL TABLES FOR TO GROUP WINNER OF EACH COUNTY:'''\n",
    "\n",
    "#Identify the Republican winner in each county:\n",
    "%sql SELECT state, state_abbreviation, county, fips, party, candidate, MAX(votes), fraction_votes, county_state FROM Republicans GROUP BY county ORDER BY state;\n",
    "%sql CREATE TABLE Republican_Winner(state TEXT NOT NULL, state_abbreviation TEXT NOT NULL, county TEXT NOT NULL, fips INTEGER NOT NULL, party TEXT NOT NULL, candidate TEXT NOT NULL, votes INTEGER NOT NULL, fraction_votes INTEGER NOT NULL, county_state TEXT NOT NULL);\n",
    "#.import republican_winners.csv Republican_Winner\n",
    "\n",
    "#Identify the Democrat winner in each county:\n",
    "%sql SELECT state, state_abbreviation, county, fips, party, candidate, MAX(votes), fraction_votes, county_state FROM Democrats GROUP BY county ORDER BY state;\n",
    "%sql CREATE TABLE Democrat_Winner(state TEXT NOT NULL, state_abbreviation TEXT NOT NULL, county TEXT NOT NULL, fips INTEGER NOT NULL, party TEXT NOT NULL, candidate TEXT NOT NULL, votes INTEGER NOT NULL, fraction_votes INTEGER NOT NULL, county_state TEXT NOT NULL);\n",
    "#.import democrat_winners.csv Democrat_Winner \n",
    "\n",
    "# Join Tables (county_facts and Republican/Democrat winner)\n",
    "%sql SELECT * FROM Republican_Winner INNER JOIN county_facts WHERE Republican_Winner.county_state = county_facts.county_state;\n",
    "%sql SELECT * FROM Democrat_Winner INNER JOIN county_facts WHERE Democrat_Winner.county_state = county_facts.county_state;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate Dataframe\n",
    "df_primary_results = pd.read_sql_query('SELECT * FROM primary_results', db) #Primary Results \n",
    "df_county_facts = pd.read_sql_query('SELECT * FROM county_facts',db) #County Facts\n",
    "df_republicans = pd.read_sql_query('SELECT * FROM Republicans',db) # Republican Table\n",
    "df_democrats = pd.read_sql_query('SELECT * FROM Democrats', db) # Democrat Table\n",
    "\n",
    "#County Facts Dictionary:\n",
    "df_county_facts_dictionary = pd.read_sql_query('SELECT * FROM county_facts_dictionary ',db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Republican Primary results\n",
    "df_republicans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Republican Primary results\n",
    "df_democrats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# County Facts data\n",
    "df_county_facts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#shape of tables:\n",
    "prim = df_primary_results.shape[0]\n",
    "rep = df_republicans.shape[0]\n",
    "dem = df_democrats.shape[0]\n",
    "print \"Primary Results:\"\n",
    "print \"Total Number of Elements = {}; Republican: {}, Democrat :{}\".format(prim,rep,dem)\n",
    "print \"Number of Features =\", df_primary_results.shape[1]\n",
    "\n",
    "#County Facts (shape):\n",
    "print \"\\nCounty Facts:\"\n",
    "print \"Total Number of Elements =\", df_county_facts.shape[0]\n",
    "print \"Number of Features =\", df_county_facts.shape[1] -4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Primary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "votes_sum = pd.read_sql_query('SELECT candidate, party, sum(votes) as sum_votes \\\n",
    "    FROM primary_results GROUP BY candidate, party ORDER BY sum_votes desc, party;',db)\n",
    "#Candidate who suspended campaign: (drop from df)\n",
    "to_del = votes_sum.loc[votes_sum['candidate'].isin(['Jeb_Bush', 'Ben_Carson','Rand_Paul',\n",
    "    'Chris_Christie','Carly_Fiorina','Rick_Santorum','Mike_Huckabee',\n",
    "    \"Martin_O'Malley\",'Marco_Rubio','_No_Preference','_Uncommitted'])].index.tolist()\n",
    "votes = votes_sum.drop(to_del)\n",
    "\n",
    "#Plots\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(y = 'candidate', x = 'sum_votes', data = votes, alpha=0.5)\n",
    "sns.plt.title('Total Votes per Candidate (Both Parties)', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# republican winner by county:\n",
    "rep_winner_county = pd.read_sql_query('SELECT candidate, count(candidate) \\\n",
    "    as count_county FROM Republican_Winner GROUP BY candidate ORDER BY count_county desc', db)\n",
    "# democrat winner by county:\n",
    "dem_winner_county = pd.read_sql_query('SELECT candidate, count(candidate) \\\n",
    "    as count_county FROM Democrat_Winner GROUP BY candidate ORDER BY count_county desc', db)\n",
    "\n",
    "#plots\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(x = 'candidate', y = 'count_county', data = rep_winner_county, alpha = 0.5)\n",
    "sns.plt.title('Total Republican Primary Counties Won', fontsize = 18)\n",
    "\n",
    "sns.plt.figure(figsize=(10,6))\n",
    "sns.barplot(x = 'candidate', y = 'count_county', data = dem_winner_county, alpha=0.5)\n",
    "sns.plt.title('Total Democrat Primary Counties Won', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataframe for Republican winners per county w/ county facts:\n",
    "democrat_data = pd.read_csv(\"democrat_winners_county_facts.csv\")\n",
    "#drop repeated columns from merge\n",
    "democrat_data.drop(democrat_data.columns[[1,3,9,10,11,63]], axis=1, inplace=True)\n",
    "\n",
    "#Dataframe for Republican winners per county w/ county facts:\n",
    "republican_data = pd.read_csv(\"republican_winners_county_facts.csv\")\n",
    "#drop repeated columns from merge\n",
    "republican_data.drop(republican_data.columns[[1,3,9,10,11,63]], axis=1, inplace=True)\n",
    "\n",
    "# Remove all rows wrt Republican candidates who suspended campaign:\n",
    "to_del = republican_data.loc[republican_data['candidate'].isin(['Jeb_Bush', \n",
    "    'Ben_Carson','Rand_Paul','Chris_Christie','Carly_Fiorina','Rick_Santorum',\n",
    "    'Mike_Huckabee',\"Marco_Rubio\",\"_No_Preference\",\"_Uncommitted\"])].index.tolist()\n",
    "republican_data = republican_data.drop(to_del)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RENAME COLUMNS: \n",
    "#remove commentted out section below to rename headers for the feature columns\n",
    "\n",
    "#republican_data or democrat_data = republican_data.rename(columns = {\n",
    "#               'PST045214':'Population 2014',\n",
    "#                'PST040210':'Population 2010',\n",
    "#                'PST120214':'Delta Pop (%) 2014',\n",
    "#                'POP010210':'Population 2010',\n",
    "#                'AGE135214':'Under 5',\n",
    "#                'AGE295214':'Under 18',\n",
    "#                'AGE775214':'Age > 65',\n",
    "#                'SEX255214':'Female (%)',\n",
    "#                'RHI125214':'White (%)',\n",
    "#                'RHI225214':'Black (%)',\n",
    "#                'RHI325214':'American Indian (%)',\n",
    "#                'RHI425214':'Asian (%)',\n",
    "#                'RHI525214':'Native Hawaiian (%)',\n",
    "#                'RHI625214':'2+ Races (%)',\n",
    "#                'RHI725214':'Hispanic (%)',\n",
    "#                'RHI825214':'White alone (%)',\n",
    "#                'POP715213':'Living same house 1+yr over (%)',\n",
    "#                'POP645213':'Foreign born (%)',\n",
    "#                'POP815213':'Other Languages (%)',\n",
    "#                'EDU635213':'High School Degree',\n",
    "#                'EDU685213':'College Degree',\n",
    "#                'VET605213':'Veterans',\n",
    "#                'LFE305213':'Mean travel time to work (minutes, Age>16+)',\n",
    "#                'HSG010214':'Housing Units',\n",
    "#                'HSG445213':'Homeownership rate',\n",
    "#                'HSG096213':'Housing units in multi-unit structures (%)',\n",
    "#                'HSG495213':'Med value of owner-occupied housing units (%)',\n",
    "#                'HSD410213':'Households',\n",
    "#                'HSD310213':'Persons per household',\n",
    "#                'INC910213':'Yr. Per capita income ($)',\n",
    "#                'INC110213':'Median household income ($)',\n",
    "#                'PVY020213':'below poverty level (%)',\n",
    "#                'BZA010213':'Private nonfarm establishments',\n",
    "#                'BZA110213':'Private nonfarm employment',\n",
    "#                'BZA115213':'Private nonfarm employment delta%)',\n",
    "#                'NES010213':'Nonemployer establishments',\n",
    "#                'SBO001207':'Total Firms',\n",
    "#                'SBO315207':'Black-owned firms (%)',\n",
    "#                'SBO115207':'American Indian owned firms, (%)',\n",
    "#                'SBO215207':'Asian-owned firms, (%)',\n",
    "#                'SBO515207':'Native Hawaiian owned firms (%)',\n",
    "#                'SBO415207':'Hispanic-owned firms (%)',\n",
    "#                'SBO015207':'Women-owned firms (%)',\n",
    "#                'MAN450207':'Manufacturers shipments($1k)',\n",
    "#                'WTN220207':'Merchant wholesaler sales ($1k)',\n",
    "#                'RTN130207':'Retail sales, ($1k)',\n",
    "#                'RTN131207':'Retail sales per capita',\n",
    "#                'AFN120207':'Accomm & food services sales ($1K)',\n",
    "#                'BPS030214':'Building permits',\n",
    "#                'LND110210':'Land area in square miles',\n",
    "#                'POP060210':'Population per sqmile'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Democrats'''\n",
    "x_columns_dem = list(democrat_data.columns[8:]) \n",
    "x_vars_dem = democrat_data[x_columns_dem] # Features\n",
    "y_vars_dem = democrat_data['candidate'] # Target Labels\n",
    "df_dem = pd.concat([x_vars_dem,y_vars_dem],axis=1) #combine Feautres/Target into one dataframe\n",
    "df_dem.drop(df_dem.columns[[3,4]],axis=1, inplace=True) #Remove Ages under 5 and 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Republicans'''\n",
    "#republican_data = republican_data.replace(['Donald_Trump','Ted_Cruz','John_Kasich'],[1,2,3])\n",
    "x_columns_rep = list(republican_data.columns[8:]) \n",
    "x_vars_rep = republican_data[x_columns_rep] # Features\n",
    "y_vars_rep = republican_data['candidate'] # Target Labels\n",
    "df_rep = pd.concat([x_vars_rep,y_vars_rep],axis=1) #combine Feautres/Target into one dataframe\n",
    "df_rep.drop(df_rep.columns[[3,4]],axis=1, inplace=True) #Remove Ages under 5 and 18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot1():\n",
    "    x_feat = \"RHI125214\"\n",
    "    y_feat = \"EDU685213\"\n",
    "    x_label = \"White (%)\"\n",
    "    y_label = \"Education (BS or Higher)\"\n",
    "    dem_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "\n",
    "def plot2():\n",
    "    x_feat = \"INC910213\"\n",
    "    y_feat = \"EDU685213\"\n",
    "    x_label = \"Per Capita Money Income ($)\"\n",
    "    y_label = \"Education (BS or Higher)\"\n",
    "    dem_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "    \n",
    "def plot3():\n",
    "    x_feat = \"INC110213\"\n",
    "    y_feat = \"RHI225214\"\n",
    "    x_label = \"Median household income ($)\"\n",
    "    y_label = \"Black or African American (%)\"\n",
    "    dem_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "    \n",
    "def plot4():\n",
    "    x_feat = \"INC110213\"\n",
    "    y_feat = \"RHI125214\"\n",
    "    x_label = \"Median household income ($)\"\n",
    "    y_label = \"White (%)\"\n",
    "    dem_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "    \n",
    "def dem_create_plot(x_feat,y_feat,x_label,y_label):\n",
    "    hue = \"candidate\"\n",
    "    dataframe = democrat_data\n",
    "    markerSize = (democrat_data['votes']/200)\n",
    "    g = sns.lmplot(x=x_feat, y=y_feat, data=dataframe, hue=hue, \n",
    "               scatter_kws={'s':markerSize,'alpha':0.7,'linewidths':1.5,'edgecolor':'w'},\n",
    "                   size=5.5, aspect=1.5)\n",
    "    g.set_xlabels(x_label, size = 18)\n",
    "    g.set_ylabels(y_label, size = 18)\n",
    "    axes = g.axes\n",
    "    g.set(ylim=(0,None))\n",
    "    g.set(xlim=(0,None))\n",
    "    sns.plt.title('Democrat Party', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Republicans\n",
    "def main():\n",
    "    plot1()\n",
    "    plot2()\n",
    "    plot3()\n",
    "    plot4()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Republican Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot1():\n",
    "    x_feat = \"RHI125214\"\n",
    "    y_feat = \"EDU685213\"\n",
    "    x_label = \"White (%)\"\n",
    "    y_label = \"Education (BS or Higher)\"\n",
    "    rep_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "\n",
    "def plot2():\n",
    "    x_feat = \"INC910213\"\n",
    "    y_feat = \"EDU685213\"\n",
    "    x_label = \"Per Capita Money Income ($)\"\n",
    "    y_label = \"Education (BS or Higher)\"\n",
    "    rep_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "    \n",
    "def plot3():\n",
    "    x_feat = \"INC110213\"\n",
    "    y_feat = \"RHI225214\"\n",
    "    x_label = \"Median household income ($)\"\n",
    "    y_label = \"Black or African American (%)\"\n",
    "    rep_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "    \n",
    "def plot4():\n",
    "    x_feat = \"INC110213\"\n",
    "    y_feat = \"RHI125214\"\n",
    "    x_label = \"Median household income ($)\"\n",
    "    y_label = \"White (%)\"\n",
    "    rep_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "\n",
    "def plot5():\n",
    "    x_feat = \"INC110213\"\n",
    "    y_feat = \"RHI725214\"\n",
    "    x_label = \"Median household income ($)\"\n",
    "    y_label = \"Hispanic(%)\"\n",
    "    rep_create_plot(x_feat,y_feat,x_label,y_label)\n",
    "\n",
    "    \n",
    "def rep_create_plot(x_feat,y_feat,x_label,y_label):\n",
    "    hue = \"candidate\"\n",
    "    dataframe = republican_data\n",
    "    markerSize = (republican_data['votes']/200)\n",
    "    g = sns.lmplot(x=x_feat, y=y_feat, data=dataframe, hue=hue, \n",
    "               scatter_kws={'s':markerSize,'alpha':0.7,'linewidths':1.5,'edgecolor':'w'},\n",
    "                   size=5.5, aspect=1.5)\n",
    "    g.set_xlabels(x_label, size = 18)\n",
    "    g.set_ylabels(y_label, size = 18)\n",
    "    axes = g.axes\n",
    "    g.set(ylim=(0,100))\n",
    "    g.set(xlim=(0,None))\n",
    "    sns.plt.title('Republican Party', fontsize = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Republicans\n",
    "def main():\n",
    "    plot1()\n",
    "    plot2()\n",
    "    plot3()\n",
    "    plot4()\n",
    "    plot5()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate Predictive Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training/Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_cols = list(df_rep.columns[:-1])  # all columns but last are features\n",
    "target_col = df_rep.columns[-1]  # last column is the target/label\n",
    "\n",
    "X_all = df_rep[feature_cols]  # feature values \n",
    "y_all = df_rep[target_col]  # corresponding targets/labels\n",
    "num_all = df_rep.shape[0]\n",
    "num_train = int(num_all - (num_all*.25))\n",
    "num_test = num_all - num_train\n",
    "\n",
    "def Stratified_Shuffle_Split(X,y,num_test):\n",
    "    sss = StratifiedShuffleSplit(y, 10, test_size=num_test, random_state = 42)\n",
    "    for train_index, test_index in sss:\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y_all, num_test)\n",
    "print \"Training Set: {0:.2f} Samples\".format(X_train.shape[0])\n",
    "print \"Testing Set: {0:.2f} Samples\".format(X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Decision_Tree():\n",
    "    n_depth = []\n",
    "    accuracy = []\n",
    "    for depth in range (1,11):\n",
    "        clf = tree.DecisionTreeClassifier(max_depth = depth, \n",
    "        min_samples_split = 20, min_samples_leaf = 20, random_state=None)\n",
    "        if clf.fit(X_train,y_train).tree_.max_depth < depth:\n",
    "            break\n",
    "        score = np.mean(cross_val_score(clf,X_train,y_train,\n",
    "                scoring ='accuracy', n_jobs=1))\n",
    "        scoring = round(score,4)\n",
    "        accuracy.append(scoring)\n",
    "        n_depth.append(depth)\n",
    "        print 'Depth: %i Accuracy: %.4f' % (depth,score)\n",
    "    DT_max_depth_plot(accuracy,n_depth)\n",
    "\n",
    "def DT_max_depth_plot(accuracy,n_depth):\n",
    "    pl.figure(figsize=(8,6))\n",
    "    pl.plot(n_depth, accuracy, label = \"Accuracy\")\n",
    "    pl.title(\"Decision Tree: Max_Depth\", fontsize = 18)\n",
    "    pl.xlabel(\"max_depth\", fontsize =14)\n",
    "    pl.ylabel(\"Accuracy\", fontsize =14)\n",
    "    pl.xlim(1,10)\n",
    "    pl.legend(loc = \"upper right\")\n",
    "    pl.tight_layout()\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Decision_Tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DT_tune_model(number_runs):\n",
    "    f1_scores = []\n",
    "    clf_dt = tree.DecisionTreeClassifier()\n",
    "    for num in range(0, number_runs):\n",
    "        X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y_all, num_test)\n",
    "        start = time.time()\n",
    "        '''Parameters:'''\n",
    "        parameters = {'max_depth':list(range(2,10)),\n",
    "                    'min_samples_leaf':(2,4,6,8,10,15,20,25,30),\n",
    "                    'min_samples_split':(2,4,6,8,10,15,20,25,30)}\n",
    "        #grid_search \n",
    "        clf_grid_search = GridSearchCV(clf_dt, parameters, scoring = 'f1')\n",
    "        \n",
    "        #Fit classifier to training data:\n",
    "        clf_grid_search.fit(X_train,y_train)\n",
    "        #Predict model on testing data:\n",
    "        pred = clf_grid_search.predict(X_test)\n",
    "        \n",
    "        #Record total run time:\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        m, s = divmod(total_time, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        print \"Total Time: %d:%02d:%02d \\n\" % (h, m, s)\n",
    "        \n",
    "        '''Classification Report:'''\n",
    "        class_report = classification_report(y_test, pred)\n",
    "        print \"Classification Report:\"\n",
    "        print class_report\n",
    "        \n",
    "        '''F1 Score'''\n",
    "        f1_scores.append(f1_score(y_test, pred, average='weighted'))\n",
    "        \n",
    "        '''Grid Search Best Parameters:'''\n",
    "        best_parameters = clf_grid_search.best_estimator_.get_params()\n",
    "        print '\\nBest Parameters:'\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "    \n",
    "    df = pd.Series(f1_scores)\n",
    "    print \"\\nF1 Score:\"\n",
    "    print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DT_tune_model(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 5, min_samples_split=10,min_samples_leaf=15)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "    \n",
    "'''Replace candidate value with name:'''\n",
    "    #df_rep.ix[df_rep.candidate == 1, 'candidate'] = 'Donald_Trump'\n",
    "    #df_rep.ix[df_rep.candidate == 2, 'candidate'] = 'Ted_Cruz'\n",
    "    #df_rep.ix[df_rep.candidate == 3, 'candidate'] = 'John_Kasich'\n",
    "    \n",
    "'''Add Labels to Features'''\n",
    "df_rep_dt = df_rep\n",
    "    #df_rep_dt.drop('candidate',axis=1,inplace = True) #drop target column\n",
    "list_of_dic = df_rep_dt.T.to_dict().values()\n",
    "vec = DictVectorizer()\n",
    "vec.fit_transform(list_of_dic).toarray()\n",
    "feature_names = vec.get_feature_names()\n",
    "    \n",
    "'''Add Target Labels'''\n",
    "target_names = ['Donald_Trump','Ted_Cruz','John_Kasich']\n",
    "\n",
    "with open(\"tree.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f)\n",
    "        \n",
    "os.unlink('tree.dot')\n",
    "    \n",
    "dot_data = StringIO() \n",
    "tree.export_graphviz(clf, out_file=dot_data,feature_names=vec.get_feature_names(),  \n",
    "                             class_names=target_names) \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "graph.write_pdf(\"tree.pdf\") \n",
    "\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(clf, out_file=dot_data,  \n",
    "                             feature_names=vec.get_feature_names(),  \n",
    "                             class_names=target_names,  \n",
    "                             filled=True, rounded=True,  \n",
    "                             special_characters=True)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier:\n",
    "clf_RF = RandomForestClassifier(n_estimators=10)\n",
    "\n",
    "#Train Classifier\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"{}:\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    train_clf_time = end - start\n",
    "    print \"Training Time (secs): {:.3f}\".format(train_clf_time)\n",
    "    return train_clf_time\n",
    "\n",
    "#Predict Labels\n",
    "def predict_labels(clf, features, target):\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    prediction_time = end - start\n",
    "    print \"Prediction Time (secs): {:.3f}\".format(prediction_time)\n",
    "    return (f1_score(target.values, y_pred, pos_label= None, average = 'macro'), prediction_time)\n",
    "    \n",
    "# Train and Predict\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print \"------------------------------------------\"\n",
    "    train_diff = train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Train and predict training set:\n",
    "    f1_score_train, pred_time_train = predict_labels(clf, X_train, y_train)\n",
    "    print \"F1 score for TRAINING set:\",(f1_score_train)\n",
    "    # Predict on test data set:\n",
    "    f1_score_test, pred_time_test = predict_labels(clf, X_test, y_test)\n",
    "    print \"F1 score for TEST set:\",(f1_score_test)\n",
    "    \n",
    "    return (f1_score_train, f1_score_test, train_diff, pred_time_test)\n",
    "\n",
    "#Run Model: (w/out Gridsearch)\n",
    "def run_model(classifiers):\n",
    "    names = feature_cols\n",
    "    for clf in classifiers:\n",
    "        df = pd.DataFrame(columns = [\n",
    "                    'Training_Size',\n",
    "                    'Testing_Size',\n",
    "                    'Training_Time',\n",
    "                    'Prediction_Time',\n",
    "                    'F1_Score_Training',\n",
    "                    'F1_Score_Testing'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y_all, num_test)\n",
    "        \n",
    "        num_times_to_run = 1\n",
    "        sizes = [X_train.shape[0]] #can change training/testing size\n",
    "        for size in sizes: \n",
    "            for x in range(0, num_times_to_run): \n",
    "                f1_score_train, f1_score_test, train_time, pred_time_test = train_predict(clf, X_train[:size], y_train[:size], X_test, y_test)\n",
    "        \n",
    "                '''Confusion Matrix: Testing Set'''\n",
    "                y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                print \"\\nConfusion Matrix:\"\n",
    "                print cm\n",
    "\n",
    "                #Feature Importance:\n",
    "                feature_imp = sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), names), \n",
    "                reverse=True)      \n",
    "                df = df.append({\n",
    "                        'Training_Size': len(X_train[:size]),\n",
    "                        'Testing_Size': X_test.shape[0],\n",
    "                        'Training_Time': train_time,\n",
    "                        'Prediction_Time': pred_time_test,\n",
    "                        'F1_Score_Training': f1_score_train,\n",
    "                        'F1_Score_Testing': f1_score_test}, \n",
    "                        ignore_index= True)\n",
    "            \n",
    "            #Feature Importance\n",
    "            columns = ['Importance','Feature']\n",
    "            df_imp = pd.DataFrame(feature_imp, columns = columns)\n",
    "            \n",
    "            #mean statistics:\n",
    "            df = df[(df.Training_Size == size)]\n",
    "            df_mean = df.mean()\n",
    "            \n",
    "            print \"**********************************************************\"\n",
    "            print \"Mean Statistics:\"\n",
    "            print df_mean\n",
    "            print \"**********************************************************\"\n",
    "            print \"Feature Importance:\"\n",
    "            print df_imp\n",
    "            print \"**********************************************************\"\n",
    "    \n",
    "    pl.figure\n",
    "    feature_plot(df_imp)\n",
    "        \n",
    "def feature_plot(df_imp):\n",
    "    ax = df_imp.plot(x='Feature', y='Importance',kind='bar',\n",
    "        figsize=(15,10), color= 'b',\n",
    "        alpha= 0.8, legend=True)\n",
    "    ax.set_title('Feature Importance', fontsize = 24)\n",
    "    ax.set_ylabel('Importance', fontsize= 16)\n",
    "    ax.set_xlabel('Feature',fontsize= 16)\n",
    "    pl.tight_layout()\n",
    "    pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_model([clf_RF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Estimators: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determining the optimal number of trees for Random Forest\n",
    "def num_estimators():\n",
    "    n_estimator = []\n",
    "    error_rate = []\n",
    "    min_estimator = 1\n",
    "    max_estimator = 200\n",
    "    X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y_all, num_test)\n",
    "    sizes = [X_train.shape[0]] #can change training/testing size\n",
    "    start = time.time()\n",
    "    for size in sizes:\n",
    "        for i in range(min_estimator, max_estimator):\n",
    "            clf = RandomForestClassifier(max_features=None, oob_score=True,random_state=None)\n",
    "            clf.set_params(n_estimators=i)\n",
    "            clf.fit(X_train, y_train).predict(X_test)\n",
    "            oob_error = round((1 - clf.oob_score_),3)\n",
    "            n_estimator.append(i)\n",
    "            error_rate.append(oob_error)\n",
    "    end = time.time()\n",
    "    total_time = (end-start)\n",
    "    m, s = divmod(total_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print \"Total Time: %d:%02d:%02d\" % (h, m, s) #hours:minutes:seconds\n",
    "    #print n_estimator \n",
    "    #print error_rate\n",
    "    pl.figure\n",
    "    error_plot(n_estimator,error_rate,min_estimator,max_estimator)\n",
    "    \n",
    "def error_plot(n_estimator,error_rate,min_estimator,max_estimator):\n",
    "        pl.figure(figsize=(8,6))\n",
    "        pl.plot(n_estimator,error_rate, linewidth=3, color = 'g', label='Random Forrest')\n",
    "        pl.ylim(0,.5)\n",
    "        pl.xlim(min_estimator,max_estimator)\n",
    "        pl.title('Random Forest: Error Rate', fontsize = 18)\n",
    "        pl.xlabel(\"num_estimators\", fontsize = 14)\n",
    "        pl.ylabel(\"OOB Error Rate\", fontsize = 14)\n",
    "        pl.tight_layout()\n",
    "        pl.legend(loc=\"upper right\",fontsize =12)\n",
    "        pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_estimators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tune Model Using GridSearch\n",
    "def RF_tune_model(number_runs):\n",
    "    clf = RandomForestClassifier(n_estimators = 30)\n",
    "    for num in range(0, number_runs):\n",
    "        start = time.time()\n",
    "        X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_all, y_all, num_test)\n",
    "        \n",
    "        '''Parameters:'''\n",
    "        parameters = {'max_depth':list(range(2,10)),\n",
    "                    'min_samples_leaf':(2,4,6,8,10,15,20,25,30),\n",
    "                    'min_samples_split':(2,4,6,8,10,15,20,25,30)}\n",
    "            \n",
    "        #grid_search \n",
    "        clf_grid_search = GridSearchCV(clf, parameters, scoring = 'f1')\n",
    "        \n",
    "        #Fit classifier to training data:\n",
    "        clf_grid_search.fit(X_train,y_train)\n",
    "                \n",
    "        #Predict model on testing data:\n",
    "        predictions = clf_grid_search.predict(X_test)\n",
    "        \n",
    "        #Record total run time:\n",
    "        end = time.time()\n",
    "        total_time = end - start\n",
    "        m, s = divmod(total_time, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        print \"Total Time: %d:%02d:%02d \\n\" % (h, m, s)                                    \n",
    "                                                     \n",
    "        '''Classification Report:'''\n",
    "        class_report = classification_report(y_test, predictions)\n",
    "        print \"Classification Report:\"\n",
    "        print class_report\n",
    "\n",
    "        '''F1 Score'''\n",
    "        f1 = round(f1_score(y_test, predictions, average='weighted'),3)\n",
    "        print \"\\nF1 Score: %s\" % f1\n",
    "        \n",
    "        '''Grid Search Best Parameters:'''\n",
    "        best_parameters = clf_grid_search.best_estimator_.get_params()\n",
    "        print '\\nBest Parameters:'\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print '\\t%s: %r' % (param_name, best_parameters[param_name])\n",
    "        \n",
    "        '''Confusion Matrix: Testing Set'''\n",
    "        clf_grid_search.fit(X_train, y_train)\n",
    "        y_true, y_pred = y_test, clf_grid_search.predict(X_test)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        pl.figure()\n",
    "        plot_confusion_matrix(cm, title='Confusion Matrix')\n",
    "        \n",
    "        print \"**************************************************\"\n",
    "        print \"\\n Confusion Matrix:\"\n",
    "        conf_matrix = pd.crosstab(y_true, y_pred, rownames=['Actual'], colnames=['Pred'], margins=True)\n",
    "        print conf_matrix\n",
    "        \n",
    "        conf_matrix_norm = conf_matrix / conf_matrix.sum(axis=1) #normalize conf matrix\n",
    "        print \"\\nNormalize Conf_Matrix:\", conf_matrix_norm\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
    "    names = ['Trump','Kasich','Cruz']\n",
    "    sns.heatmap(cm,annot=True, fmt='')\n",
    "    pl.title(title, fontsize =20)\n",
    "    tick_marks = np.arange(len(names))\n",
    "    pl.xticks(tick_marks,names, rotation=45)\n",
    "    pl.yticks(tick_marks,names)\n",
    "    pl.tight_layout()\n",
    "    pl.ylabel('True label', fontsize =14)\n",
    "    pl.xlabel('Predicted label', fontsize =14)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF_tune_model(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def doPCA():\n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(df_scale)\n",
    "    return pca\n",
    "\n",
    "def plot_explained_variance(ex_var):\n",
    "    pl.figure(figsize=(8,6))\n",
    "    pl.bar(range(1,6), ex_var, alpha=0.5, align='center', color = 'b')\n",
    "    pl.xlabel('Number of Principal Components', fontsize = 14)\n",
    "    pl.ylabel('Explained Variance', fontsize =14)\n",
    "    pl.title('Explained Variance Ratio', fontsize = 18)\n",
    "    pl.tight_layout()\n",
    "    pl.show\n",
    "\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "columns = X_all.columns\n",
    "scale = preprocessing.scale(X_all)\n",
    "df_scale = pd.DataFrame(scale, columns=columns)\n",
    "#df_scale.head()\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "pca = doPCA()\n",
    "columns = X_all.columns\n",
    "df_pca = pd.DataFrame(pca.components_, columns = columns)\n",
    "df_pca.index.names = ['PC']\n",
    "print \"Principal Component Analysis:\"\n",
    "print df_pca.head()\n",
    "\n",
    "ex_var = pca.explained_variance_ratio_\n",
    "df_var = pd.Series(ex_var)\n",
    "df_var.sort(ascending=False)\n",
    "\n",
    "df_var.index.names = ['PC']\n",
    "print \"\\nExplained Variance of Each Component:\"\n",
    "print df_var.head()\n",
    "\n",
    "plot_explained_variance(ex_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_scale = df_scale\n",
    "from sklearn import decomposition\n",
    "\n",
    "def run_RF_PCA(number_runs):\n",
    "    for num in range(0, number_runs):\n",
    "        start = time.time()\n",
    "        X_train, X_test, y_train, y_test = Stratified_Shuffle_Split(X_scale, y_all, num_test)\n",
    "\n",
    "        # Dimension Reduction\n",
    "        pca = decomposition.RandomizedPCA(n_components=20, whiten=True)\n",
    "        fit = pca.fit(X_train)\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators = 30)\n",
    "        clf.fit(X_train_pca, y_train)\n",
    "        \n",
    "        pred = clf.predict(X_test_pca)\n",
    "        class_report = classification_report(y_test, pred) #report\n",
    "        f1 = round(f1_score(y_test, pred, average='weighted'),3) #f1 score\n",
    "        \n",
    "        '''Confusion Matrix: Testing Set'''\n",
    "        y_true, y_pred = y_test, pred\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        pl.figure()\n",
    "        plot_confusion_matrix(cm, title='Confusion Matrix')\n",
    "\n",
    "        print \"Classification Report:\"\n",
    "        print class_report\n",
    "        print \"\\nF1 Score: %s\" % f1\n",
    "        print \"\\nConfusion Matrix\"\n",
    "        print cm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_RF_PCA(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
